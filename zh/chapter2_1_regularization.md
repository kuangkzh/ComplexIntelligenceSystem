# 构建智能——正则：缩小采样空间

在本章中我们将要介绍用于构建智能的各种方法，主要是深度学习中常用的各种手段。
我们不会去介绍每一种算法的原理和公式推导，这些过程已经十分完善地出现在各种论文研究和网络博客介绍中了。

本章旨在帮助读者建立一种思考上的直觉，即依前文所述，所有智能都源于同样的原理，遵循同样的发展规律，展现出同样的性质，
那么在一种智能中生效的构建手段，就能平行地迁移到另一种智能上。
我们在其中需要做的，就是在构建时想清楚智能产生的几个要素，即系统的状态空间、目标分布和预期的目标分布。

在第一章对智能原理的介绍中，我们提到过智能的诞生过程对我们如何构建智能有两点重要启发。
第一是在无法对命题直接求解时，可以对其逆否命题通过采样筛选的手段排除错误答案，从而完成近似求解。
第二是尽可能弥合工具目标和实际目标函数之间的gap，避免目标的传导失真。
这两点为我们提供了两个方向的智能构建技巧。

在本节中将要介绍的是第一点，即对整个状态空间引入先验假设，通过缩小采样空间的方式降低采样成本，加速求解过程。


## 正则项

最容易想到的应该是正则项损失，在模型训练时，有时会在损失函数中加上L1或L2正则项对模型参数进行约束。
L2正则项限制了模型参数值的大小，L1则在限制参数值大小的同时希望令参数稀疏化。
这是一种简单粗暴的约束方式，它假定了参数的分布不会距离原点太远，
或者说不需要那些过于偏离的参数就可以达到预期的目标，引入那些偏离值反而会增大收敛的成本和风险。

在其他没有大量显式参数的智能系统中，很少见到使用范数约束参数的方式。
不过如果将正则项看作一种通过简单假设强行缩减大量求解空间的手段，那我们可以在其他系统中找到许多类似的手段。
它通常表现为一种强制的标准，例如在企业招聘中往往会直接规定招人的年龄、学历等硬性要求，
这并非是由于在低学历的求职者中没有任何人才，而是仅仅从高学历者中筛选就已经足够满足企业需求了。
企业不愿意在低学历的采样空间中付出巨大的成本，哪怕低学历人群中可能有远超高学历者的人才。
硬性筛选也可以规避许多风险，即使内部员工在招聘上联合舞弊，将学历达标的作弊者送入公司，也比将完全没有教育背景的作弊者送入公司好得多。


## 结构复用

结构复用普遍存在于所有的智能中，每一种结构的复用都对应了一种对于状态空间性质的深刻认识。
深度学习普遍运用着各种复用的结构，CNN假定了数据具有空间不变性并且短程依赖占主导地位，RNN假定了序列数据具有马尔可夫性，
Transformer假定了序列数据具有空间不变性且任意位置间都可能有依赖关系。
尽管有不少研究论证了CNN与全连接层的等价性，还有万能逼近定理指出无限宽的单层网络可以拟合任何连续函数，
但没有人会真的使用一个非常宽的单层网络去拟合一个复杂的数据集，因为更庞大的状态空间需要大得多的数据集才能拟合。

复用的结构实际上把一个问题中通用的复杂性解耦了出来在一起解决，这种解决问题的方式十分普遍。
在数学中，我们将代数从数的运算中抽离出来，又将抽象代数和代数分离，
这样我们对群、环、域的研究就可以通用地应用在四元数、线性代数、代数拓扑等代数系统，
从而广泛运用在机器学习、图形学、量子力学等所有领域，而不需要在每个领域都投入大量人力发展各自的数学体系。

在大型企业中，往往将同一套组织架构复用在不同部门。
一个部门里总是由领导、人事、还有其他普通员工组成，这些员工又被分成了前端、开发、数据、设计、产品、销售等各种岗位，每个岗位都有各自规定清晰的工作职责。
事实上我们知道一个员工完全有可能胜任多种职责，例如一个同时是好的程序员又是好的销售的员工，可以为公司节省更多人力成本。
但如果想让每个人都完全发挥自己的才能，就需要花费大量时间让员工探索自己在不同领域的能力，
同时在跨工种的工作结果上也会难以衡量，从而增加不能胜任工作的风险。
因此公司会宁愿抽象出工作内容相似的多个工种，将每个员工培训成更加标准的螺丝钉，并为这套螺丝钉设计一套匹配的稳定运行的生产模式。

事实上，一种商业模式的成功就在于找到某种可以不断复用的模式，通过解耦再聚合复杂性的方法，降低复用的边际成本。
例如连锁店将进货、出售、品牌这些关键问题解耦为一套复用的模式。网络平台将网络信息传播解耦成文本、聊天、图片、视频等多种模式。
复杂问题被解决后，再将结果泛化到通用的场景上实现增长和盈利就变得十分简单了。

本文的理论实际上也是一种复用结构，本文试图将广泛存在于社会的、经济的、自然的、人工的智能系统演化规律和性质归纳总结进入一套理论中，
使得同样的理论能在多种不同领域中生效，再将不同领域中泛化应用的情况通过复用部分进行共享，
从而使得本理论的解释力不断完善，同时其他应用领域也能够互相推动进步。
当然截止本文写作时，本理论依然处于在作者知识范围内的训练阶段，还没有泛化到作者未知的领域上。


## 混沌工程

混沌工程是软件工程中的术语，指通过主动制造故障场景，提前发现系统脆弱部分，并依据系统在故障压力下的表现优化系统的抗风险能力。
我们把这个定义延伸到更广泛的系统构建上，它实际指出了一个假设，即系统的每个子部分对最终目标的实现都应该具有相同的贡献，
且都应该具有相同的抗风险能力，而不应该出现单点失效的情况。
在深度学习中，最常见的手段就是Dropout，按一定概率随机对模型中的参数置零，
还有一些研究中会在训练中加入随机噪声，故意引入噪声风险，从而防止模型过拟合。

现代企业要求员工休假，实际上在无形之中就提高了系统的抗风险能力，尽管休假制度普遍并不是为这一目的而设立的。
在一些要求更高的企业中，确实存在随机强制带薪休假制度，该制度在不提前通知的情况下，随机地让员工进行一段较长时间的带薪休假（通常以月为单位），
这与让官员每隔几年异地调任一样，是为了避免岗位权力过于集中在个人手中，从而造成单点风险。



## 总结

正则化方法的特点是，在系统状态空间中引入某种强力假设，直接缩减了大量可能的系统空间，因此大大降低了系统的构建成本，也能够避免假设外的泛化风险。
然而作为代价的是，每一中假设都在限制系统的灵活性，从而也限制了系统的表现上限，
但如果不进行正则化，我们可能连获得可用的系统表现都做不到。
一些人将企业规模扩大后流程低效归结于大企业病，从另一个角度来看或许是因为大企业会面临远比小公司多的风险，
而约束不强、流程灵活的小型公司在成长过程中很容易就会遇到毁灭性风险，所谓大企业病也是一种自限性的保护手段。

越是在大规模的系统中，越难在庞大的状态空间里找到可用解，所面临的风险点也越多，也就越需要更多的正则化约束。
正则化方法的性能损耗和成本收益与假设的有效性强相关，一个理想的假设应该尽可能将具有风险的空间排除出去，同时保留那些具有潜力的空间。
这需要依靠对系统空间内在联系的深刻洞察作出先验判断。

如今的LLM对此的假设是我们可以仅在文本空间就能找到人类智能，且文本序列是以长程依赖主导的平移不变性空间，可以使用Transformer架构建模。
借助上千亿token的文本数据，我们能让上百亿参数的LLM诞生媲美人类智能的对话能力。
其实这个假设实际并不够好，首先文本空间并不是人类智能的全部，且平移不变和长程依赖两个假设有些太弱了，
只不过我们恰好能方便地从文本渠道获取大量廉价的数据，足以通过大量无死角的空间采样找到可用的解。
可以很明显感受到，这种方式训练出来的智能过于臃肿，模型实际在参数中硬编码记住了大量知识。
如果具有足够强的假设能够剥离这些不必要的复杂性，我猜想仅需100M的热参数、1B的冷参数（按需加载），
加上100B的非编码知识记忆库，就足以完全实现人类平均的智能水平（包括对话、语音、视觉、学习、运动能力）。

